{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOKdeU1X+J8tdAcMXju65/X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElaheTorabi/Masters-Thesis/blob/main/Spatial_Autocorrelation_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spatial Autocorrelation Analysis of Fuel Consumption Data"
      ],
      "metadata": {
        "id": "LrSRdY0SJLGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install & import required libraries"
      ],
      "metadata": {
        "id": "vbucNmo9-r-U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-eq2dWYpsva"
      },
      "outputs": [],
      "source": [
        "!pip install geopandas folium openpyxl\n",
        "import pandas as pd\n",
        "import folium\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the Excel files to Colab"
      ],
      "metadata": {
        "id": "DxtIjtJE-x3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "C4BsSopcp_j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read and combine all Excel files"
      ],
      "metadata": {
        "id": "BxvlGGLW-2nZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = []\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    df = pd.read_excel(filename)\n",
        "\n",
        "    # Keep only one row per site (coordinates & ID are constant)\n",
        "    site_info = df[[\n",
        "        'TAG_NAME',\n",
        "        'DEVICE_ID',\n",
        "        'DUTYSTATION_NAME',\n",
        "        'OGI_LAT',\n",
        "        'OGI_LONG'\n",
        "    ]].drop_duplicates()\n",
        "\n",
        "    dfs.append(site_info)\n",
        "\n",
        "# Combine all sites into one dataframe\n",
        "sites_df = (\n",
        "    pd.concat(dfs, ignore_index=True)\n",
        "      .dropna(subset=['DEVICE_ID'])\n",
        "      .drop_duplicates(subset='DEVICE_ID')\n",
        ")\n",
        "\n",
        "\n",
        "# Final clean\n",
        "sites_df = sites_df.drop_duplicates(subset='DEVICE_ID')\n",
        "\n",
        "sites_df"
      ],
      "metadata": {
        "id": "hV8XKeihqIfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an interactive map"
      ],
      "metadata": {
        "id": "eD7iENA_-6EG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_center = [\n",
        "    sites_df['OGI_LAT'].mean(),\n",
        "    sites_df['OGI_LONG'].mean()\n",
        "]\n",
        "\n",
        "m = folium.Map(location=map_center, zoom_start=7)"
      ],
      "metadata": {
        "id": "X9Un7OtSqKSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add site markers with ID labels"
      ],
      "metadata": {
        "id": "kZ74e7b9_Xpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in sites_df.iterrows():\n",
        "    popup_text = f\"\"\"\n",
        "    <b>Duty Station:</b> {row['DUTYSTATION_NAME']}<br>\n",
        "    <b>Device ID:</b> {row['DEVICE_ID']}<br>\n",
        "    <b>Tag Name:</b> {row['TAG_NAME']}\n",
        "    \"\"\"\n",
        "\n",
        "    folium.Marker(\n",
        "        location=[row['OGI_LAT'], row['OGI_LONG']],\n",
        "        popup=popup_text,\n",
        "        icon=folium.Icon(color='blue', icon='info-sign')\n",
        "    ).add_to(m)\n",
        "\n",
        "m\n"
      ],
      "metadata": {
        "id": "wFUwZuraqOd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing Fuel consumption"
      ],
      "metadata": {
        "id": "OMaefd_UAYH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = []\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    df = pd.read_excel(filename)\n",
        "\n",
        "    # --- Time handling ---\n",
        "    df['Date_Hour_Desc'] = pd.to_datetime(df['Date_Hour_Desc'])\n",
        "    df = df.sort_values('Date_Hour_Desc')\n",
        "\n",
        "    # --- Observed consumption ---\n",
        "    df['Consumption_observed'] = -df['LevelLiters'].diff()\n",
        "    df.loc[df['Consumption_observed'] < 0, 'Consumption_observed'] = pd.NA\n",
        "\n",
        "    df['Consumption_observed'] = (\n",
        "        df['Consumption_observed']\n",
        "        .rolling(window=3, center=True, min_periods=1)\n",
        "        .mean()\n",
        "    )\n",
        "\n",
        "    # --- Outlier cleaning (Observed) ---\n",
        "    Q1, Q3 = df[\"Consumption_observed\"].quantile([0.25, 0.75])\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    outliers = (\n",
        "        (df[\"Consumption_observed\"] < Q1 - 1.5 * IQR) |\n",
        "        (df[\"Consumption_observed\"] > Q3 + 1.5 * IQR)\n",
        "    )\n",
        "\n",
        "    df.loc[outliers, \"Consumption_observed\"] = pd.NA\n",
        "\n",
        "    df[\"Consumption_observed\"] = df[\"Consumption_observed\"].interpolate(\n",
        "        method=\"linear\", limit_direction=\"both\"\n",
        "    )\n",
        "\n",
        "    dfs.append(df)\n",
        "\n",
        "all_df = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "SUWjsYqRqmiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aggregate observed consumption per site per year"
      ],
      "metadata": {
        "id": "s5RM0pJUAzGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_df['Date_Hour_Desc'] = pd.to_datetime(all_df['Date_Hour_Desc'])\n",
        "all_df['year'] = all_df['Date_Hour_Desc'].dt.year"
      ],
      "metadata": {
        "id": "92GhMaAF8uuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agg_obs = (\n",
        "    all_df\n",
        "    .dropna(subset=['Consumption_observed'])\n",
        "    .groupby(['DEVICE_ID', 'year'])\n",
        "    .agg(\n",
        "        Consumption_observed_mean=('Consumption_observed', 'mean'),\n",
        "        OGI_LAT=('OGI_LAT', 'first'),\n",
        "        OGI_LONG=('OGI_LONG', 'first'),\n",
        "        DUTYSTATION_NAME=('DUTYSTATION_NAME', 'first')\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "agg_obs.head()"
      ],
      "metadata": {
        "id": "vDmzQ_3YyOuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing spatial autocorrelation using Moran’s I for each year by k-nearest neighbors"
      ],
      "metadata": {
        "id": "3T_0MHR-DZ5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from libpysal.weights import KNN\n",
        "from esda.moran import Moran\n",
        "\n",
        "results = []\n",
        "\n",
        "for year in agg_obs['year'].unique():\n",
        "    df_year = agg_obs[agg_obs['year'] == year]\n",
        "\n",
        "    if len(df_year) < 4:\n",
        "        continue\n",
        "\n",
        "    gdf_knn = gpd.GeoDataFrame(\n",
        "        df_year,\n",
        "        geometry=gpd.points_from_xy(df_year.OGI_LONG, df_year.OGI_LAT),\n",
        "        crs=\"EPSG:4326\"\n",
        "    ).to_crs(epsg=32634)\n",
        "\n",
        "    w = KNN.from_dataframe(gdf_knn, k=2)\n",
        "    w.transform = 'r'\n",
        "\n",
        "    y = gdf_knn['Consumption_observed_mean'].values\n",
        "    moran = Moran(y, w)\n",
        "\n",
        "    results.append({\n",
        "        'year': year,\n",
        "        'Moran_I': moran.I,\n",
        "        'p_value': moran.p_sim\n",
        "    })\n",
        "\n",
        "moran_yearly_knn = pd.DataFrame(results)\n",
        "moran_yearly_knn\n"
      ],
      "metadata": {
        "id": "f0_csP-sx6pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aggregate temperature-corrected consumption per site per year"
      ],
      "metadata": {
        "id": "r9GlJbydBlrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure datetime\n",
        "all_df['Date_Hour_Desc'] = pd.to_datetime(all_df['Date_Hour_Desc'])\n",
        "all_df['year'] = all_df['Date_Hour_Desc'].dt.year\n",
        "\n",
        "agg_corr = (\n",
        "    all_df\n",
        "    .dropna(subset=['Consumption_corrected'])\n",
        "    .groupby(['DEVICE_ID', 'year'])\n",
        "    .agg(\n",
        "        Consumption_corrected_mean=('Consumption_corrected', 'mean'),\n",
        "        OGI_LAT=('OGI_LAT', 'first'),\n",
        "        OGI_LONG=('OGI_LONG', 'first'),\n",
        "        DUTYSTATION_NAME=('DUTYSTATION_NAME', 'first')\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "agg_corr.head()"
      ],
      "metadata": {
        "id": "Pv9KmOYJ9Uju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing spatial autocorrelation of temperature-corrected consumption using Moran’s I for each year by k-nearest neighbors"
      ],
      "metadata": {
        "id": "H1RZt_cuE6yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from libpysal.weights import DistanceBand\n",
        "from esda.moran import Moran\n",
        "import geopandas as gpd\n",
        "\n",
        "results_corr = []\n",
        "\n",
        "for year in agg_corr['year'].unique():\n",
        "    df_year = agg_corr[agg_corr['year'] == year]\n",
        "\n",
        "    # Skip years with too few sites\n",
        "    if len(df_year) < 4:\n",
        "        continue\n",
        "\n",
        "    # GeoDataFrame\n",
        "    gdf_corr_knn = gpd.GeoDataFrame(\n",
        "        df_year,\n",
        "        geometry=gpd.points_from_xy(df_year.OGI_LONG, df_year.OGI_LAT),\n",
        "        crs=\"EPSG:4326\"\n",
        "    ).to_crs(epsg=32634)\n",
        "\n",
        "    # Spatial weights (same as observed!)\n",
        "    w = KNN.from_dataframe(gdf_corr_knn, k=2)\n",
        "    w.transform = 'r'\n",
        "\n",
        "    # Moran's I\n",
        "    y = gdf_corr_knn['Consumption_corrected_mean'].values\n",
        "    moran = Moran(y, w)\n",
        "\n",
        "    results_corr.append({\n",
        "        'year': year,\n",
        "        'Moran_I_corrected': moran.I,\n",
        "        'p_value_corrected': moran.p_sim\n",
        "    })\n",
        "\n",
        "moran_corrected_corr_knn = pd.DataFrame(results_corr)\n",
        "moran_corrected_corr_knn\n"
      ],
      "metadata": {
        "id": "pZTz3KwBx7bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing the results"
      ],
      "metadata": {
        "id": "m9khsFT_FOEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "moran_compare = (\n",
        "    moran_yearly_knn\n",
        "    .merge(moran_corrected_corr_knn, on='year', how='inner')\n",
        ")\n",
        "\n",
        "moran_compare"
      ],
      "metadata": {
        "id": "VBpH0-hix_lQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
